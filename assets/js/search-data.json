{
  
    
        "post0": {
            "title": "A neural network for elastography (part 2)",
            "content": "Introduction . In part 1, we talked about elastography, and we created a model that predicts the stiffness from a given displacement field. The displacement field had no noise, so we decided to add some to make it looks more realistic. Our goal is to beat that model. . Introduction and Data Preparation sections will be almost identical to part 1, so we won&#39;t comment much about it. For details, check part 1. . As mentioned in part 1, it is easy to run all the code we show. Just click on the &quot;Open in Colab&quot; button on the top of this page. It will open this page as a Colab notebook. . First, if you&#39;re using colab, you need to install PyTorch and fastai. . !pip install torch !pip install fastai !pip install fastai --upgrade -q . Then, we download and unzip the data we&#39;re going to use. . import os.path if not os.path.exists(&#39;MNIST_input_files.zip&#39;): !wget https://open.bu.edu/bitstream/handle/2144/38693/MNIST_input_files.zip if not os.path.exists(&#39;FEA_displacement_results_step5.zip&#39;): !wget https://open.bu.edu/bitstream/handle/2144/38693/FEA_displacement_results_step5.zip !unzip -n &quot;MNIST_input_files.zip&quot; -d &quot;.&quot; !unzip -n &quot;FEA_displacement_results_step5.zip&quot; -d &quot;uniaxial/&quot; . We import some libraries. . import pandas as pd import torch from fastai.vision.all import * . Data preparation . We load the data from text files to PyTorch tensor. . df = pd.read_csv(&#39;MNIST_input_files/mnist_img_train.txt&#39;, sep=&#39; &#39;, header=None) imgs_train = torch.tensor(df.values) df = pd.read_csv(&#39;MNIST_input_files/mnist_img_test.txt&#39;, sep=&#39; &#39;, header=None) imgs_valid = torch.tensor(df.values) imgs_train.shape, imgs_valid.shape . (torch.Size([60000, 784]), torch.Size([10000, 784])) . df = pd.read_csv(&#39;uniaxial/FEA_displacement_results_step5/summary_dispx_train_step5.txt&#39;, sep=&#39; &#39;, header=None) ux5s_train = torch.tensor(df.values) df = pd.read_csv(&#39;uniaxial/FEA_displacement_results_step5/summary_dispy_train_step5.txt&#39;, sep=&#39; &#39;, header=None) uy5s_train = torch.tensor(df.values) df = pd.read_csv(&#39;uniaxial/FEA_displacement_results_step5/summary_dispx_test_step5.txt&#39;, sep=&#39; &#39;, header=None) ux5s_valid = torch.tensor(df.values) df = pd.read_csv(&#39;uniaxial/FEA_displacement_results_step5/summary_dispy_test_step5.txt&#39;, sep=&#39; &#39;, header=None) uy5s_valid = torch.tensor(df.values) ux5s_train.shape, uy5s_train.shape, ux5s_valid.shape, uy5s_valid.shape . (torch.Size([60000, 784]), torch.Size([60000, 784]), torch.Size([10000, 784]), torch.Size([10000, 784])) . We reshape the data. . ux5s_train = torch.reshape(ux5s_train, (-1,1,28,28)) uy5s_train = torch.reshape(uy5s_train, (-1,1,28,28)) ux5s_valid = torch.reshape(ux5s_valid, (-1,1,28,28)) uy5s_valid = torch.reshape(uy5s_valid, (-1,1,28,28)) imgs_train = torch.reshape(imgs_train, (-1,1,28,28)) imgs_valid = torch.reshape(imgs_valid, (-1,1,28,28)) ux5s_train.shape, uy5s_train.shape, ux5s_valid.shape, uy5s_valid.shape, imgs_train.shape, imgs_valid.shape . (torch.Size([60000, 1, 28, 28]), torch.Size([60000, 1, 28, 28]), torch.Size([10000, 1, 28, 28]), torch.Size([10000, 1, 28, 28]), torch.Size([60000, 1, 28, 28]), torch.Size([10000, 1, 28, 28])) . The displacement field is inverted, so we fix it. . show_image(imgs_train[2], cmap=&#39;Greys&#39;) show_image(uy5s_train[2], cmap=&#39;Greys&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fadf0be4e48&gt; . ux5s_train = torch.flip(ux5s_train, dims=[1,2]) uy5s_train = torch.flip(uy5s_train, dims=[1,2]) ux5s_valid = torch.flip(ux5s_valid, dims=[1,2]) uy5s_valid = torch.flip(uy5s_valid, dims=[1,2]) . show_image(imgs_train[2], cmap=&#39;Greys&#39;) show_image(uy5s_train[2], cmap=&#39;Greys&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fadf0beb2b0&gt; . We convert from pixel values to stiffness. . imgs_train = (imgs_train / 255.) * 99. + 1. imgs_valid = (imgs_valid / 255.) * 99. + 1. imgs_train = imgs_train / 100. imgs_valid = imgs_valid / 100. . imgs_train.min(), imgs_valid.min(), imgs_train.max(), imgs_valid.max() . (tensor(0.0100), tensor(0.0100), tensor(1.), tensor(1.)) . We put horizontal and vertical displacements into the same tensor. . us_train = torch.cat([ux5s_train, uy5s_train], dim=1) us_valid = torch.cat([ux5s_valid, uy5s_valid], dim=1) us_train.shape, us_valid.shape . (torch.Size([60000, 2, 28, 28]), torch.Size([10000, 2, 28, 28])) . We do some cleaning. . del ux5s_train; del uy5s_train; del ux5s_valid; del uy5s_valid . Okay, now we have some new stuff. . This fastai Transform is the same from part 1, except that it adds some noise. We take the noise from a Normal Distribution with mean equals 0, and standard deviation equals 0.1. We will see that noise makes the task more challenging. . class GetNormalizedData(Transform): def __init__(self, us, imgs, mean, std, noise_std): self.us, self.imgs = us, imgs self.mean, self.std = mean, std self.noise_std = noise_std def encodes(self, i): us_norm = torch.true_divide((self.us[i] - self.mean.view(2,1,1)), self.std.view(2,1,1)) us_with_noise = us_norm + torch.randn(2,28,28)*self.noise_std return (us_with_noise.float(), self.imgs[i].float()) . We calculate the mean and standard deviation from our dataset so we can normalize the data. . us_mean = torch.mean(us_train, dim=[0,2,3]) us_std = torch.std(us_train, dim=[0,2,3]) . We create fastai TfmdLists and DataLoaders. . noise_std = 0.1 train_tl= TfmdLists(range(len(us_train[:])), GetNormalizedData(us_train[:], imgs_train[:], us_mean, us_std, noise_std) ) valid_tl= TfmdLists(range(len(us_valid[:])), GetNormalizedData(us_valid[:], imgs_valid[:], us_mean, us_std, noise_std) ) . dls = DataLoaders.from_dsets(train_tl, valid_tl, bs=64) if torch.cuda.is_available(): dls = dls.cuda() . Okay, let&#39;s take a look at our batch. . x,y = dls.one_batch() x.shape, y.shape, x.mean(), x.std() . (torch.Size([64, 2, 28, 28]), torch.Size([64, 1, 28, 28]), tensor(-0.0054), tensor(1.0122)) . show_image(x[0][1], cmap=&#39;Greys&#39;) show_image(y[0], cmap=&#39;Greys&#39;) show_image(x[1][1], cmap=&#39;Greys&#39;) show_image(y[1], cmap=&#39;Greys&#39;) show_image(x[2][1], cmap=&#39;Greys&#39;) show_image(y[2], cmap=&#39;Greys&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f572dbc5978&gt; . Okay, 0.1 for the standard deviation seems to be a good value for a challenging but yet possible task. We see from the images above that we can still identify the numbers in the displacement field, but the details are hard to see. . Training . Remember, our goal is to beat the model created in part 1. That model got a validation loss of 0.0065, so that&#39;s our goal. The task now is definitely more difficult, so we will use a deeper neural network. . We will not train it all at once (we probably could, try it). We begin training the same model we used in part 1. Then, we remove the output layer and add a new hidden layer and a new output layer. We train the whole model. After that, we repeat the process of removing/adding layers and training them. . We create a class Base, which will be the input/hidden layer, and a class Head, which will be the output layer. We multiply the activations by 1.1 after the sigmoid, so the model returns values between 0 and 1.1. . class Base(nn.Module): def __init__(self, n_in, n_out): super(Base, self).__init__() self.conv = nn.Conv2d(n_in, n_out, kernel_size=5, stride=1, padding=2, padding_mode=&#39;reflect&#39;, bias=True) self.relu = nn.ReLU() def forward(self, x): return self.relu(self.conv(x)) . class Head(nn.Module): def __init__(self, n_in, n_out, y_range): super(Head, self).__init__() self.y_range = y_range self.conv = nn.Conv2d(n_in, n_out, 5, 1, 2, padding_mode=&#39;reflect&#39;, bias=True) self.sigmoid = nn.Sigmoid() def forward(self, x): return self.sigmoid(self.conv(x))*self.y_range . We begin with the same architecture used in part 1. . cnn1 = nn.Sequential(Base(2, 4), Head(4, 1, 1.1)) . l1 = Learner(dls, cnn1, loss_func=F.mse_loss, model_dir=&#39;&#39;) . We find a good candidate for the learning rate, and then we train the model. . l1.lr_find() . SuggestedLRs(lr_min=0.33113112449646, lr_steep=0.010964781977236271) . l1.fit_one_cycle(10,lr_max=1e-2) . epoch train_loss valid_loss time . 0 | 0.024701 | 0.023902 | 00:18 | . 1 | 0.020117 | 0.019674 | 00:18 | . 2 | 0.019051 | 0.018667 | 00:18 | . 3 | 0.018855 | 0.018620 | 00:18 | . 4 | 0.018318 | 0.018213 | 00:18 | . 5 | 0.017984 | 0.018009 | 00:18 | . 6 | 0.017937 | 0.017854 | 00:18 | . 7 | 0.017773 | 0.017722 | 00:18 | . 8 | 0.017673 | 0.017584 | 00:19 | . 9 | 0.017758 | 0.017525 | 00:19 | . We can save it. . Note: All saved models are available in this repo. . l1.path = Path(&#39;&#39;) l1.save(&#39;02_cnn1_ep10&#39;) . Let&#39;s see how our model is doing. . preds, targets, losses = l1.get_preds(with_loss=True) . _, indices = torch.sort(losses, descending=True) for i in indices[:3]: show_image(torch.cat([preds, torch.ones(preds.shape[0],1,28,1), targets], dim=3)[i], cmap=&#39;Greys_r&#39;) . I_preds = ((preds*100)-1)*(255/99) I_targets = ((targets*100)-1)*(255/99) I_error = torch.abs(I_preds - I_targets) I_mean = torch.mean(I_error) I_std = torch.std(I_error) I_mean, I_std . (tensor(14.6327), tensor(30.8624)) . Mean and standard deviation are 14.6 and 30.9, respectively. It does not seem terrible, but we are still far from our goal. Let&#39;s add more layers. . We take the first layer of our previous model and add two new layers. . cnn2 = nn.Sequential(l1.model[0], Base(4, 8), Head(8, 1, 1.1)) l2 = Learner(dls, cnn2, loss_func=F.mse_loss, model_dir=&#39;&#39;) . We find a good learning rate and train our model. . l2.lr_find() . SuggestedLRs(lr_min=0.005754399299621582, lr_steep=0.0012022644514217973) . l2.fit_one_cycle(5, lr_max=3e-3) . epoch train_loss valid_loss time . 0 | 0.015613 | 0.015378 | 00:18 | . 1 | 0.014453 | 0.014299 | 00:19 | . 2 | 0.014103 | 0.013915 | 00:19 | . 3 | 0.013683 | 0.013562 | 00:18 | . 4 | 0.013607 | 0.013543 | 00:18 | . l2.fit_one_cycle(5, lr_max=3e-3) . epoch train_loss valid_loss time . 0 | 0.013642 | 0.013651 | 00:18 | . 1 | 0.013382 | 0.013282 | 00:18 | . 2 | 0.013294 | 0.013129 | 00:18 | . 3 | 0.013178 | 0.013031 | 00:19 | . 4 | 0.013074 | 0.013030 | 00:19 | . l2.path = Path(&#39;&#39;) l2.save(&#39;models/02_cnn2_ep10&#39;) . Let&#39;s see if the model is improving. . preds, targets, losses = l2.get_preds(with_loss=True) . _, indices = torch.sort(losses, descending=True) for i in indices[:3]: show_image(torch.cat([preds, torch.ones(preds.shape[0],1,28,1), targets], dim=3)[i], cmap=&#39;Greys_r&#39;) . I_preds = ((preds*100)-1)*(255/99) I_targets = ((targets*100)-1)*(255/99) I_error = torch.abs(I_preds - I_targets) I_mean = torch.mean(I_error) I_std = torch.std(I_error) I_mean, I_std . (tensor(12.2046), tensor(26.7411)) . Nice, the mean and the standard deviation decreased. Let&#39;s add a new layer. . Again, we keep everything but the last layer and add two new layers (Base and Head). . cnn3 = nn.Sequential(l2.model[0], l2.model[1], Base(8, 16), Head(16, 1, 1.1)) l3 = Learner(dls, cnn3, loss_func=F.mse_loss, model_dir=&#39;&#39;) . We find a good learning rate and train the model. . l3.lr_find() . SuggestedLRs(lr_min=0.33113112449646, lr_steep=0.0003981071640737355) . l3.fit_one_cycle(5, lr_max=1e-2) . epoch train_loss valid_loss time . 0 | 0.012930 | 0.012544 | 00:19 | . 1 | 0.011336 | 0.010928 | 00:19 | . 2 | 0.010565 | 0.010285 | 00:19 | . 3 | 0.010030 | 0.010060 | 00:19 | . 4 | 0.009895 | 0.009768 | 00:19 | . l3.fit_one_cycle(5, lr_max=1e-2) . epoch train_loss valid_loss time . 0 | 0.010616 | 0.010767 | 00:19 | . 1 | 0.010378 | 0.010520 | 00:19 | . 2 | 0.009992 | 0.009603 | 00:19 | . 3 | 0.009642 | 0.009459 | 00:19 | . 4 | 0.009406 | 0.009376 | 00:19 | . l3.path = Path(&#39;&#39;) l3.save(&#39;models/02_cnn3_ep10&#39;) . Nice, validation loss is under 0.01. Let&#39;s add more layers. . cnn4 = nn.Sequential(l3.model[0], l3.model[1], l3.model[2], Base(16, 32), Head(32, 1, 1.1)) l4 = Learner(dls, cnn4, loss_func=F.mse_loss, model_dir=&#39;&#39;) . l4.lr_find() . SuggestedLRs(lr_min=0.03019951581954956, lr_steep=0.0005754399462603033) . l4.fit_one_cycle(5, lr_max=3e-3) . epoch train_loss valid_loss time . 0 | 0.009254 | 0.009672 | 00:20 | . 1 | 0.008698 | 0.008634 | 00:20 | . 2 | 0.008317 | 0.008167 | 00:20 | . 3 | 0.008171 | 0.007967 | 00:20 | . 4 | 0.007987 | 0.007927 | 00:20 | . l4.fit_one_cycle(5, lr_max=3e-3) . epoch train_loss valid_loss time . 0 | 0.008445 | 0.008203 | 00:20 | . 1 | 0.008310 | 0.008244 | 00:19 | . 2 | 0.008095 | 0.008137 | 00:20 | . 3 | 0.007941 | 0.007829 | 00:19 | . 4 | 0.007764 | 0.007718 | 00:19 | . The loss increased in the first epochs. This could be because the learning rate is too high for the first layers. Next time we&#39;ll try something different. . l4.path = Path(&#39;&#39;) l4.save(&#39;models/02_cnn4_ep10&#39;) . Let&#39;s add more layers. . cnn5 = nn.Sequential(*l4.model[0:4], Base(32, 64), Head(64, 1, 1.1)) l5 = Learner(dls, cnn5, loss_func=F.mse_loss, model_dir=&#39;&#39;) . l5.lr_find() . SuggestedLRs(lr_min=0.33113112449646, lr_steep=0.0003981071640737355) . l5.fit_one_cycle(5, lr_max=3e-3) . epoch train_loss valid_loss time . 0 | 0.007929 | 0.007879 | 00:21 | . 1 | 0.007663 | 0.007467 | 00:21 | . 2 | 0.007260 | 0.007151 | 00:20 | . 3 | 0.006991 | 0.006932 | 00:21 | . 4 | 0.006843 | 0.006826 | 00:21 | . This time we run lr_find() again to train with a different learning rate. . l5.lr_find() . SuggestedLRs(lr_min=2.2908675418875645e-07, lr_steep=6.309573450380412e-07) . l5.fit_one_cycle(5, lr_max=1e-5) . epoch train_loss valid_loss time . 0 | 0.007022 | 0.006942 | 00:21 | . 1 | 0.006975 | 0.006896 | 00:21 | . 2 | 0.006920 | 0.006869 | 00:21 | . 3 | 0.006785 | 0.006712 | 00:21 | . 4 | 0.006744 | 0.006693 | 00:21 | . l5.path = Path(&#39;&#39;) l5.save(&#39;models/02_cnn5_std=0.1_ep10&#39;) . Validation loss was 0.0065 in part 1, so we&#39;re very close. Let&#39;s add more layers. . cnn6 = nn.Sequential(*l5.model[0:5], Base(64, 128), Head(128, 1, 1.1)) l6 = Learner(dls, cnn6, loss_func=F.mse_loss, model_dir=&#39;&#39;) . l6.lr_find() . SuggestedLRs(lr_min=0.006918309628963471, lr_steep=0.00019054606673307717) . l6.fit_one_cycle(5, lr_max=3e-3) . epoch train_loss valid_loss time . 0 | 0.007262 | 0.007157 | 00:23 | . 1 | 0.007013 | 0.006997 | 00:23 | . 2 | 0.006735 | 0.006644 | 00:23 | . 3 | 0.006336 | 0.006322 | 00:23 | . 4 | 0.006169 | 0.006190 | 00:23 | . l6.lr_find() . SuggestedLRs(lr_min=1.318256749982538e-07, lr_steep=9.12010818865383e-07) . l6.fit_one_cycle(5, lr_max=1e-5) . epoch train_loss valid_loss time . 0 | 0.006353 | 0.006404 | 00:23 | . 1 | 0.006392 | 0.006440 | 00:23 | . 2 | 0.006234 | 0.006220 | 00:23 | . 3 | 0.006029 | 0.006085 | 00:23 | . 4 | 0.005865 | 0.006039 | 00:23 | . l6.path = Path(&#39;&#39;) l6.save(&#39;models/02_cnn6_ep10&#39;) . We did it! Our validation loss is less than 0.0065. . Results . Let&#39;s now check how good the predictions are. . inputs, preds, targets, losses = l6.get_preds(with_input=True, with_loss=True) . On the left, we show predictions that had the ten worst losses. On the right, we show the targets. . _, indices = torch.sort(losses, descending=True) for i in indices[:10]: show_image(torch.cat([preds, torch.ones(preds.shape[0],1,28,1), targets], dim=3)[i], cmap=&#39;Greys_r&#39;) . It seems nice. Even the worst predictions capture some details of the handwritten digits. . Let&#39;s calculate the same metrics we used in part 1. . I_preds = ((preds*100)-1)*(255/99) I_targets = ((targets*100)-1)*(255/99) I_error = torch.abs(I_preds - I_targets) I_mean = torch.mean(I_error) I_std = torch.std(I_error) I_mean, I_std . (tensor(6.7603), tensor(18.8619)) . In part 1, the mean was 8.5, and the standard deviation was 19. Our new model got a mean equals 6.7, and a standard deviation equals 18.9. . So we did it! We beat the model created in part 1, even though here, we added noise in the data, while in part 1, we did not. Of course, we could try to keep improving the model. For instance, we could do some hyper-parameter tweaking, include data from other experiments (such as shear or confined compression), add more layers, etc. However, this is left as an exercise for the reader üòÜ. . To recap, in this notebook, we&#39;ve created a model that, given a noisy two-dimensional displacement field, predicts the stiffness throughout a body that has a hard inclusion. Below, we show one example of input (noisy displacement field), prediction (predicted stiffness), and target (correct stiffness). We see that our model has determined the shape of the hard inclusion with a good resolution, despite the noise in the displacement field. . i = 123 show_image(inputs[i][0], cmap=&#39;Greys_r&#39;, title=&#39;Input: Horizontal displacement&#39;) show_image(inputs[i][1], cmap=&#39;Greys_r&#39;, title=&#39; Input: Vertical displacement &#39;) show_image(preds[i], cmap=&#39;Greys_r&#39;, title=&#39; Output: Predicted stiffness &#39;) show_image(targets[i], cmap=&#39;Greys_r&#39;, title=&#39; Target: Correct stiffness &#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fade5192128&gt; .",
            "url": "https://lucas-almeida-r.github.io/blog/neural%20networks/elastography/2020/10/09/elastography_2.html",
            "relUrl": "/neural%20networks/elastography/2020/10/09/elastography_2.html",
            "date": " ‚Ä¢ Oct 9, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "A neural network for elastography (part 1)",
            "content": "Introduction . Elastography is a medical imaging modality that informs us about the stiffness of soft tissue. This information is relevant because many diseases form hard tissues. For instance, tumors, thrombus, and diseased liver tissue are usually stiffer than their surrounding tissues. . The basic idea is to: . Apply some deformation in the tissue. It can be done manually, with a probe, or we could even use our heartbeat. | Measure how much the tissue displaces. This is the displacement field, which can be measured with ultrasound, magnetic resonance imaging (MRI), etc. | Calculate the stiffness of the tissue or some other elastic property. | The third step is called Inverse Problem. It receives this name because the usual problem is determining the displacement field from a known stiffness (this would be the Direct Problem), and the inverse problem does the opposite. There are mainly two ways to solve the inverse problem: . Directly: we solve the governing equations of the problem. This approach is relatively fast and simple, but it suffers from the noise present in the displacement field measured. | Iteratively: we keep updating the stiffness until we find one such as when we solve the direct problem, we obtain a displacement field very similar to the measured one. This approach is, in theory, more robust to noise, but it is much slower and more complicated to use in practice because it involves some parameter tweaking. | . If you want to know more about elastography and these two approaches, check out Fovargue, Nordsletten and Sinkus (2018). . We will solve this inverse problem differently. We will use a neural network! Recently, some authors seem to be giving some attention to this approach. See, for instance, Kibria and Rivaz (2018) and Solamen, Shi and Amoh (2018). The main advantage is that this approach is fast (after the neural network is trained, of course) and robust to noise. A major limitation is the necessity of training data, but transfer learning could be a way to overcome it. Models could be pre-trained with synthetic data and then fine-tuned with a small number of real clinical data samples. . Creating synthetic data takes some time, but lucky for us, Lejeune (2020) did it. She built the Mechanical MNIST, which is a collection of datasets of finite element simulations, where heterogeneous blocks composed of Neo-Hookean material are subjected to some kind of loading. It can be a uniaxial extension, confined compression, shear, etc. The blocks are essentially a soft material with a hard inclusion, whose shape is a handwritten digit from the famous MNIST Dataset. The value of each pixel was converted to a Young modulus, which was used in the finite element simulations to obtain the displacement field. Young modulus is a measure of the stiffness of solid material, so let&#39;s call it just &quot;stiffness&quot;. . Enough talk, let&#39;s code! . We will make our neural network with PyTorch and fastai. PyTorch is a widely used Python library developed by Facebook for machine and deep learning. Fastai is a deep learning library built on Pytorch. It provides high-level and low-level components that simplifies many aspects of a deep learning project. . . Note: I will assume that you are familiar with neural networks, PyTorch, and fastai. If you want to learn more about them, I recommend the Deep Learning Specialization by deeplearning.ai on Coursera for the first and the fastai MOOC for the last two. These courses are not short, but they are great. . It&#39;s very easy to run the code we show. Just click on the &quot;Open in Colab&quot; button on top of this page. It will open this page as a Colab notebook. PyTorch and fastai are not installed in Colab by default, so we need to install them manually. . !pip install torch !pip install fastai !pip install fastai --upgrade -q . Now we download and unzip the data that we will use for the training. We will use only the fifth step of the uniaxial extension from Mechanical MNIST. . The data contain the displacement field and handwritten digits from MNIST Dataset, which represents the heterogeneous material (hard inclusion in a soft background). . import os.path if not os.path.exists(&#39;MNIST_input_files.zip&#39;): !wget https://open.bu.edu/bitstream/handle/2144/38693/MNIST_input_files.zip if not os.path.exists(&#39;FEA_displacement_results_step5.zip&#39;): !wget https://open.bu.edu/bitstream/handle/2144/38693/FEA_displacement_results_step5.zip !unzip -n &quot;MNIST_input_files.zip&quot; -d &quot;.&quot; # replace &quot;-n&quot; with &quot;-o&quot; if you wish to overwrite existing files !unzip -n &quot;FEA_displacement_results_step5.zip&quot; -d &quot;uniaxial/&quot; . Let&#39;s import some libraries. . from pathlib import Path import pandas as pd import torch from fastai.vision.all import * . Data preparation . We load the data from the text files to PyTorch tensors. Don&#39;t worry, the data is small. . df = pd.read_csv(&#39;MNIST_input_files/mnist_img_train.txt&#39;, sep=&#39; &#39;, header=None) imgs_train = torch.tensor(df.values) df = pd.read_csv(&#39;MNIST_input_files/mnist_img_test.txt&#39;, sep=&#39; &#39;, header=None) imgs_valid = torch.tensor(df.values) imgs_train.shape, imgs_valid.shape . (torch.Size([60000, 784]), torch.Size([10000, 784])) . df = pd.read_csv(&#39;uniaxial/FEA_displacement_results_step5/summary_dispx_train_step5.txt&#39;, sep=&#39; &#39;, header=None) ux5s_train = torch.tensor(df.values) df = pd.read_csv(&#39;uniaxial/FEA_displacement_results_step5/summary_dispy_train_step5.txt&#39;, sep=&#39; &#39;, header=None) uy5s_train = torch.tensor(df.values) df = pd.read_csv(&#39;uniaxial/FEA_displacement_results_step5/summary_dispx_test_step5.txt&#39;, sep=&#39; &#39;, header=None) ux5s_valid = torch.tensor(df.values) df = pd.read_csv(&#39;uniaxial/FEA_displacement_results_step5/summary_dispy_test_step5.txt&#39;, sep=&#39; &#39;, header=None) uy5s_valid = torch.tensor(df.values) ux5s_train.shape, uy5s_train.shape, ux5s_valid.shape, uy5s_valid.shape . (torch.Size([60000, 784]), torch.Size([60000, 784]), torch.Size([10000, 784]), torch.Size([10000, 784])) . We reshape the tensors to show them as regular images with one channel. . ux5s_train = torch.reshape(ux5s_train, (-1,1,28,28)) uy5s_train = torch.reshape(uy5s_train, (-1,1,28,28)) ux5s_valid = torch.reshape(ux5s_valid, (-1,1,28,28)) uy5s_valid = torch.reshape(uy5s_valid, (-1,1,28,28)) imgs_train = torch.reshape(imgs_train, (-1,1,28,28)) imgs_valid = torch.reshape(imgs_valid, (-1,1,28,28)) ux5s_train.shape, uy5s_train.shape, ux5s_valid.shape, uy5s_valid.shape, imgs_train.shape, imgs_valid.shape . (torch.Size([60000, 1, 28, 28]), torch.Size([60000, 1, 28, 28]), torch.Size([10000, 1, 28, 28]), torch.Size([10000, 1, 28, 28]), torch.Size([60000, 1, 28, 28]), torch.Size([10000, 1, 28, 28])) . Let&#39;s take a look at our data. . show_image(imgs_train[2], cmap=&#39;Greys&#39;) show_image(uy5s_train[2], cmap=&#39;Greys&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd5559b47f0&gt; . The displacement field seems inverted. Let&#39;s fix it. . ux5s_train = torch.flip(ux5s_train, dims=[1,2]) uy5s_train = torch.flip(uy5s_train, dims=[1,2]) ux5s_valid = torch.flip(ux5s_valid, dims=[1,2]) uy5s_valid = torch.flip(uy5s_valid, dims=[1,2]) . show_image(imgs_train[2], cmap=&#39;Greys&#39;) show_image(uy5s_train[2], cmap=&#39;Greys&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd5559bbc18&gt; . Ok, much better. . Now let&#39;s convert the pixel values (0-255) to stiffness values (0.01-1). This step is not really necessary. Our network could directly predict pixel values instead of stiffness. . The original formula from Lejeune (2020) is $$ mathrm{stiffness} = frac{ mathrm{pixel}}{255} , 99 + 1, $$ but we include a division by 100 because it is convenient for visualization purposes. Again, we could skip this conversion. . imgs_train = (imgs_train / 255.) * 99. + 1. imgs_valid = (imgs_valid / 255.) * 99. + 1. imgs_train = imgs_train / 100. imgs_valid = imgs_valid / 100. . imgs_train.min(), imgs_valid.min(), imgs_train.max(), imgs_valid.max() . (tensor(0.0100), tensor(0.0100), tensor(1.), tensor(1.)) . Let&#39;s merge the horizontal and vertical displacements into one tensor, so each component of the displacement field is in a separate channel. . us_train = torch.cat([ux5s_train, uy5s_train], dim=1) us_valid = torch.cat([ux5s_valid, uy5s_valid], dim=1) us_train.shape, us_valid.shape . (torch.Size([60000, 2, 28, 28]), torch.Size([10000, 2, 28, 28])) . We do some cleaning. . del ux5s_train; del uy5s_train; del ux5s_valid; del uy5s_valid . Now, we create fastai DataLoaders from a low-level API. . The first step is to create our Transform. Fastai Transforms are classes that modify the dataset when the batch is being prepared. . Our Transform is simple. It receives an integer i and returns a tuple (x,y), where x and y are the i-th element of us_train and imgs_train, respectively. Our Transform also normalizes these elements. . class GetNormalizedData(Transform): def __init__(self, us, imgs, mean, std): self.us, self.imgs = us, imgs self.mean, self.std = mean, std def encodes(self, i): us_normalized = torch.true_divide((self.us[i] - self.mean.view(2,1,1)), self.std.view(2,1,1)) return (us_normalized.float(), self.imgs[i].float()) . We calculate the mean and the standard deviation of our data. . us_mean = torch.mean(us_train, dim=[0,2,3]) us_std = torch.std(us_train, dim=[0,2,3]) . We create a TfmdLists (Transformed Lists), which is just an object that will apply some Transforms in a list when the time is right. It is lazy. . So it is like the range(...) is our dataset, but the Transform will receive the elements of this range(...) and return a tuple of the actual data. . train_tl= TfmdLists(range(len(us_train)), GetNormalizedData(us_train, imgs_train, us_mean, us_std) ) valid_tl= TfmdLists(range(len(us_valid)), GetNormalizedData(us_valid, imgs_valid, us_mean, us_std) ) . Once we have the TfmdLists, we can easily create the Dataloaders. If we have access to a GPU, it will use it. . dls = DataLoaders.from_dsets(train_tl, valid_tl, bs=64) if torch.cuda.is_available(): dls = dls.cuda() . Let&#39;s take a look at a batch. The mean is next to zero and the standard deviation to one, it seems right. . x,y = dls.one_batch() x.shape, y.shape, x.mean(), x.std() . (torch.Size([64, 2, 28, 28]), torch.Size([64, 1, 28, 28]), tensor(0.0210), tensor(0.9808)) . Training . From the images we have seen above, our task does not seem difficult. . Let&#39;s use a simple architecture. It is just a CNN with an input layer and an output layer. We know that the targets range from 0.01 to 1, so we also apply a scaled sigmoid to return values between 0 and 1.1. The target values are numbers between 0 and 1, so why we multiply the sigmoid layer by 1.1? We do it because, otherwise, the preceding layer would have to return a very high value to the output of the sigmoid layer be equal to 1. . We choose the parameters of the convolutions so that the activations have shape a (n,28,28), where n is free to be any number. . class CNN(nn.Module): def __init__(self): super(CNN, self).__init__() self.conv1 = nn.Conv2d(2, 4, 5, 1, 2, padding_mode=&#39;reflect&#39;, bias=True) self.conv2 = nn.Conv2d(4, 1, 5, 1, 2, padding_mode=&#39;reflect&#39;, bias=True) self.sigmoid = nn.Sigmoid() self.relu = nn.ReLU() def forward(self, x): h = self.relu(self.conv1(x)) return self.sigmoid(self.conv2(h)) * 1.1 . We create a fastai Learner. This object groups the data (dataloaders), the architecture, the loss function, and the optimizer (ADAM by default). It has everything that we need to start the training. . l = Learner(dls, CNN(), loss_func=F.mse_loss, model_dir=&#39;&#39;) . We find a good learning rate. lr_find trains the model a bit with exponentially growing learning rates and report the loss. This technique was introduced by Smith (2017). We choose 0.01 because it is close to the point where the slope is the steepest. . l.lr_find() . SuggestedLRs(lr_min=0.33113112449646, lr_steep=0.007585775572806597) . Now we train! . fit_one_cycle uses the 1cycle policy proposed by Smith and Topin (2017). It&#39;s a training strategy where the learning rate increases until it reaches lr_max, and then it decreases. The momentum does the opposite. Check out the documentation for more details. . l.fit_one_cycle(10,lr_max=1e-2) . epoch train_loss valid_loss time . 0 | 0.018236 | 0.016336 | 00:42 | . 1 | 0.009801 | 0.009679 | 00:42 | . 2 | 0.008643 | 0.009191 | 00:42 | . 3 | 0.007818 | 0.007774 | 00:42 | . 4 | 0.007161 | 0.007132 | 00:42 | . 5 | 0.006956 | 0.006896 | 00:42 | . 6 | 0.006797 | 0.007023 | 00:42 | . 7 | 0.006638 | 0.006642 | 00:42 | . 8 | 0.006591 | 0.006579 | 00:42 | . 9 | 0.006548 | 0.006541 | 00:42 | . We can save the model. . Note: The saved model is avaiable in this repo. . l.path = Path(&#39;&#39;) l.save(&#39;models/01_cnn_ep10&#39;) . Results . Let&#39;s check the predictions of the model. . preds, targets, losses = l.get_preds(with_loss=True) . On the left, we have the predictions, and on the right, the targets. . for i in range(0,10): show_image(torch.cat([preds, torch.ones(preds.shape[0],1,28,1), targets], dim=3)[i], cmap=&#39;Greys_r&#39;) . It looks good. Let&#39;s now check the predictions that had the top losses. . _, indices = torch.sort(losses, descending=True) for i in indices[:10]: show_image(torch.cat([preds, torch.ones(preds.shape[0],1,28,1), targets], dim=3)[i], cmap=&#39;Greys_r&#39;) . It looks good, as well. Now, we check the lowest losses. . for i in indices[-10:]: show_image(torch.cat([preds, torch.ones(preds.shape[0],1,28,1), targets], dim=3)[i], cmap=&#39;Greys_r&#39;) . Okay, it seems like our model is doing a good job. . Lejeune (2020) also made a model for the same task. She evaluated her model using the mean and the standard deviation of the absolute error of the test set (which is our validation set). She constructed a simple FNN with scikit-learn and obtained a mean equals 13 and a standard deviation equals 79, in pixel values. . Let&#39;s calculate these metrics for our model. . px_preds = ((preds*100)-1)*(255/99) px_targets = ((targets*100)-1)*(255/99) px_error = torch.abs(px_preds - px_targets) px_mean = torch.mean(px_error) px_std = torch.std(px_error) px_mean, px_std . (tensor(8.5147), tensor(19.0121)) . Nice! A mean equals 8.5, and a standard deviation equals 19. Better than the FNN! . Now let&#39;s try to make the data more realistic. In part 2, we will add some noise to the displacement field, and we will try to beat the model we have just made. . See you in part 2! .",
            "url": "https://lucas-almeida-r.github.io/blog/neural%20networks/elastography/2020/10/08/elastography_1.html",
            "relUrl": "/neural%20networks/elastography/2020/10/08/elastography_1.html",
            "date": " ‚Ä¢ Oct 8, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi! My name is Lucas Almeida Rocha, and I‚Äôm a Master‚Äôs student at the University of S√£o Paulo, where I study material mechanics. In my free time, I like programming (among other things, of course), so I‚Äôve ‚Äúcreated‚Äù1 this blog to share some projects that I can‚Äôt explain in just one readme page on Github. . This website is powered by fastpages, which is a blogging platform that natively supports Jupyter notebooks in addition to other formats.¬†&#8617; . |",
          "url": "https://lucas-almeida-r.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://lucas-almeida-r.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}